{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, \"rt\"):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, \"rt\")\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for user, book, rating in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    data.append([user, book, rating])\n",
    "\n",
    "train_data = data[:190000]\n",
    "valid_data = data[190000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerBook = defaultdict(list)\n",
    "\n",
    "for user, book, rating in train_data:\n",
    "    ratingsPerUser[user].append(rating)\n",
    "    ratingsPerBook[book].append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train_data)\n",
    "nUsers = len(ratingsPerUser)\n",
    "nBooks = len(ratingsPerBook)\n",
    "users = list(ratingsPerUser.keys())\n",
    "books = list(ratingsPerBook.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingMean = sum([int(d[2]) for d in train_data]) / N\n",
    "\n",
    "alpha = ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiases = defaultdict(float)\n",
    "bookBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    J = sum((predictions - labels) ** 2)/ len(labels)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, book):\n",
    "    if user in userBiases and book in bookBiases:\n",
    "        return alpha + userBiases[user] + bookBiases[book]\n",
    "    elif user in bookBiases and book not in bookBiases:\n",
    "        return alpha + userBiases[user]\n",
    "    elif user not in bookBiases and book in bookBiases:\n",
    "        return alpha + bookBiases[book]\n",
    "    else:\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global bookBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1 : nUsers + 1]))\n",
    "    bookBiases = dict(zip(books, theta[1 + nUsers :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb, l1, data):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(user, book) for user, book, _ in data]\n",
    "    cost = MSE(numpy.array(predictions), numpy.array(labels))\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    #for u in userBiases:\n",
    "     #   cost += lamb * userBiases[u] ** 2\n",
    "    #for i in bookBiases:\n",
    "    #    cost += lamb * bookBiases[i] ** 2\n",
    "    cost += lamb*(1 - l1)*(sum(numpy.array(list(userBiases.values())) ** 2) + sum(numpy.array(list(bookBiases.values())) ** 2))\n",
    "    cost += lamb * l1 * (sum(numpy.abs(numpy.array(list(userBiases.values())))) + sum(numpy.abs(numpy.array(list(bookBiases.values())))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = lambda x : numpy.copysign(1, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb, l1, data):\n",
    "    unpack(theta)\n",
    "    N = len(data)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dBookBiases = defaultdict(float)\n",
    "    for user, book, rating in data:\n",
    "        pred = prediction(user, book)\n",
    "        diff = pred - float(rating)\n",
    "        dalpha += 2 / N * diff\n",
    "        dUserBiases[user] += 2 / N * diff\n",
    "        dBookBiases[book] += 2 / N * diff\n",
    "    \n",
    "    for user in userBiases:\n",
    "        dUserBiases[user] += 2 * lamb * (1 - l1) * userBiases[user] + lamb * l1 * sign(userBiases[user])\n",
    "        \n",
    "    for book in bookBiases:\n",
    "        dBookBiases[book] += 2 * lamb * (1 - l1) * bookBiases[book] + lamb * l1 * sign(bookBiases[book])\n",
    "    \n",
    "    dtheta =  [dalpha] + [dUserBiases[u] for u in users] + [dBookBiases[b] for b in books]\n",
    "        \n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [float(d[2]) for d in train_data]\n",
    "train_alwaysPredictMean = [float(alpha) for d in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4735475011336192"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(numpy.array(train_alwaysPredictMean), numpy.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.4814337548468803\n",
      "MSE = 2.293363042210713\n",
      "MSE = 1.4733842256204268\n",
      "MSE = 1.473227103721692\n",
      "MSE = 1.4725990813230208\n",
      "MSE = 1.4700944348665983\n",
      "MSE = 1.46019493925109\n",
      "MSE = 1.422502400155635\n",
      "MSE = 1.1920321823433524\n",
      "MSE = 1.0652601296486968\n",
      "MSE = 1.0556963211312334\n",
      "MSE = 1.0271727365580325\n",
      "MSE = 1.0100593263853004\n",
      "MSE = 0.974624655744501\n",
      "MSE = 0.9614706154715367\n",
      "MSE = 0.9610117515322717\n",
      "MSE = 0.9609499302934326\n",
      "MSE = 0.9607453651108362\n",
      "MSE = 0.9600801807950957\n",
      "MSE = 0.9584255663030808\n",
      "MSE = 0.9546043429224209\n",
      "MSE = 0.9484265146077718\n",
      "MSE = 2.443036789965412\n",
      "MSE = 0.9485763956595791\n",
      "MSE = 0.9429558474438441\n",
      "MSE = 0.9408678320692607\n",
      "MSE = 0.9407037166985477\n",
      "MSE = 0.9407123173393946\n",
      "MSE = 0.9403278124625067\n",
      "MSE = 1.5795306684235078\n",
      "MSE = 0.9409995931607942\n",
      "MSE = 0.9400813076391846\n",
      "MSE = 0.9936147202541333\n",
      "MSE = 0.9371427041881008\n",
      "MSE = 0.9328843868809991\n",
      "MSE = 0.9288125865276382\n",
      "MSE = 0.9276648001549389\n",
      "MSE = 0.9281207843889614\n",
      "MSE = 0.9276840862399007\n",
      "MSE = 0.9275826037372401\n",
      "MSE = 0.9271230469224823\n",
      "MSE = 0.9264038758035025\n",
      "MSE = 0.9251623596073855\n",
      "MSE = 0.923207621505111\n",
      "MSE = 2.3570814786797216\n",
      "MSE = 0.9231588380515644\n",
      "MSE = 0.9218442454884602\n",
      "MSE = 0.9214132131248317\n",
      "MSE = 0.9214116137614585\n",
      "MSE = 0.9214509501175144\n",
      "MSE = 0.9215761277848166\n",
      "MSE = 0.9217676072632371\n",
      "MSE = 0.9219445298378437\n",
      "MSE = 0.9230672615537471\n",
      "MSE = 0.9205756721537226\n",
      "MSE = 0.9178441238660877\n",
      "MSE = 0.9187902795979886\n",
      "MSE = 0.9178651041076935\n",
      "MSE = 0.9177864339225541\n",
      "MSE = 0.9177236089693972\n",
      "MSE = 0.9174580161707462\n",
      "MSE = 0.9172283617858643\n",
      "MSE = 0.9171799591506686\n",
      "MSE = 0.916538200644674\n",
      "MSE = 0.9153694781662568\n",
      "MSE = 0.9143464742363947\n",
      "MSE = 0.9139434238694508\n",
      "MSE = 0.9136617761670434\n",
      "MSE = 0.9136408046081561\n",
      "MSE = 0.9134110515082479\n",
      "MSE = 0.9121035048301338\n",
      "MSE = 0.9130089215865625\n",
      "MSE = 0.9123185618032845\n",
      "MSE = 0.9122405192452878\n",
      "MSE = 0.9168653312034343\n",
      "MSE = 0.9123651100970764\n",
      "MSE = 0.9122760324665609\n",
      "MSE = 0.9131575937714974\n",
      "MSE = 0.9124624805462744\n",
      "MSE = 0.9113563899288799\n",
      "MSE = 0.911072158671623\n",
      "MSE = 0.910591246447393\n",
      "MSE = 0.9108421939753569\n",
      "MSE = 0.9107902205697425\n",
      "MSE = 0.9103317801225419\n",
      "MSE = 0.9106612452501001\n",
      "MSE = 0.9104853005915232\n",
      "MSE = 0.9100425986103716\n",
      "MSE = 0.9096512794337214\n",
      "MSE = 1.3604692029203862\n",
      "MSE = 0.9096318191160644\n",
      "MSE = 0.9094545814491487\n",
      "MSE = 0.9094268766018044\n",
      "MSE = 0.9094250249676186\n",
      "MSE = 0.9094070910802238\n",
      "MSE = 0.9093527280939037\n",
      "MSE = 0.9092917084566182\n",
      "MSE = 0.9158229412091123\n",
      "MSE = 0.9092781269564678\n",
      "MSE = 0.9091945296598744\n",
      "MSE = 0.9091774475362286\n",
      "MSE = 0.909195739604238\n",
      "MSE = 0.9092521564995286\n",
      "MSE = 0.9093563786434403\n",
      "MSE = 0.9108905214475771\n",
      "MSE = 0.9093169639192342\n",
      "MSE = 0.9095076394485564\n",
      "MSE = 0.9096107414417144\n",
      "MSE = 0.9109451260476865\n",
      "MSE = 0.9099195108457689\n",
      "MSE = 0.9097149322218824\n",
      "MSE = 0.9093513064159487\n",
      "MSE = 0.909462141524811\n",
      "MSE = 0.90899591465941\n",
      "MSE = 0.9090669951302778\n",
      "MSE = 0.9091324527201423\n",
      "MSE = 0.9091301917442979\n",
      "MSE = 0.9091090030749653\n",
      "MSE = 0.9091212077379336\n",
      "MSE = 0.9091986253792483\n",
      "MSE = 0.9091343189430803\n",
      "MSE = 0.9091240268121809\n",
      "MSE = 0.909097124317426\n",
      "MSE = 0.909055338112941\n",
      "MSE = 0.9090074125072148\n",
      "MSE = 0.9089755680277743\n",
      "MSE = 0.910315754141266\n",
      "MSE = 0.9089924086539466\n",
      "MSE = 0.9090030965909486\n",
      "MSE = 0.9090565426173755\n",
      "MSE = 0.909070496725621\n",
      "MSE = 0.9090879366477304\n",
      "MSE = 0.9090054049214682\n",
      "MSE = 0.9090682408771259\n",
      "MSE = 0.9090612686389542\n",
      "MSE = 0.9090100653289359\n",
      "MSE = 0.9089406607019874\n",
      "MSE = 0.908900280056881\n",
      "MSE = 0.9088773709070989\n",
      "MSE = 0.9089035295967824\n",
      "MSE = 0.9088766521704614\n",
      "MSE = 0.9088324966487368\n",
      "MSE = 0.9087662019931882\n",
      "MSE = 0.9087959027001791\n",
      "MSE = 0.9088199307148327\n",
      "MSE = 0.9088432754094206\n",
      "MSE = 0.9088616100655952\n",
      "MSE = 0.9089667605143019\n",
      "MSE = 0.9088542146285872\n",
      "MSE = 0.908857884505148\n",
      "MSE = 0.9088336035712841\n",
      "MSE = 0.9087853508447198\n",
      "MSE = 0.908736208809962\n",
      "MSE = 0.9090281172725193\n",
      "MSE = 0.9087351380537022\n",
      "MSE = 0.9087010490061582\n",
      "MSE = 0.9086070655745748\n",
      "MSE = 0.908670601201474\n",
      "MSE = 0.9086660428400726\n",
      "MSE = 0.9086789847772135\n",
      "MSE = 0.9086850558884829\n",
      "MSE = 0.9093396795619593\n",
      "MSE = 0.9086881851262094\n",
      "MSE = 0.9086984991660176\n",
      "MSE = 0.9089603283940833\n",
      "MSE = 0.9087107342595279\n",
      "MSE = 0.9087035662682861\n",
      "MSE = 0.9086686435109108\n",
      "MSE = 0.9086671504365446\n",
      "MSE = 0.908667099047721\n",
      "MSE = 0.9086519390771547\n",
      "MSE = 0.9086194101502885\n",
      "MSE = 0.9086280157803087\n",
      "MSE = 0.9086333426346432\n",
      "MSE = 0.9086366037439734\n",
      "MSE = 0.9086642172682733\n",
      "MSE = 0.9086416766641747\n",
      "MSE = 0.9086416634588533\n",
      "MSE = 0.9086477411384156\n",
      "MSE = 0.9086505275007907\n",
      "MSE = 0.9086788396737264\n",
      "MSE = 0.9086831349587468\n",
      "MSE = 0.9086786758962395\n",
      "MSE = 0.9086773830554841\n",
      "MSE = 0.9086826053188728\n",
      "MSE = 0.9085636728020849\n",
      "MSE = 0.9086720492866662\n",
      "MSE = 0.9086725793832013\n",
      "MSE = 0.908671784595397\n",
      "MSE = 0.9086776330684917\n",
      "MSE = 0.9086712755398436\n",
      "MSE = 0.9086682833934184\n",
      "MSE = 0.9086650698217209\n",
      "MSE = 0.9086686027856012\n",
      "MSE = 0.9086710375285342\n",
      "MSE = 0.9086737081094358\n",
      "MSE = 0.9086724634758315\n",
      "MSE = 0.9088909094385538\n",
      "MSE = 0.9086809438509066\n",
      "MSE = 0.9086769494293334\n",
      "MSE = 0.9086578390760865\n",
      "MSE = 0.9086442855342083\n",
      "MSE = 0.9086551953483654\n",
      "MSE = 0.908652812080863\n",
      "MSE = 0.9086526589934152\n"
     ]
    }
   ],
   "source": [
    "theta = scipy.optimize.fmin_l_bfgs_b(cost,[alpha] + [0.0] * (nUsers + nBooks), derivative,args=(train_labels, 0.00001, 0.25, train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1100949524615094\n"
     ]
    }
   ],
   "source": [
    "unpack(theta[0])\n",
    "valid_labels = [float(d[2]) for d in valid_data]\n",
    "valid_predictions = [prediction(u, b) for u,b,_ in valid_data]\n",
    "print(MSE(numpy.array(valid_predictions), numpy.array(valid_labels)))\n",
    "theta_model1 = theta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Max.User Bias</th>\n",
       "      <td>u81539151</td>\n",
       "      <td>1.228056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min.User Bias</th>\n",
       "      <td>u48313610</td>\n",
       "      <td>-3.671815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max.Book Bias</th>\n",
       "      <td>b19925500</td>\n",
       "      <td>1.309103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min.Book Bias</th>\n",
       "      <td>b84091840</td>\n",
       "      <td>-1.644747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID     Value\n",
       "Max.User Bias  u81539151  1.228056\n",
       "Min.User Bias  u48313610 -3.671815\n",
       "Max.Book Bias  b19925500  1.309103\n",
       "Min.Book Bias  b84091840 -1.644747"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ub = (max(userBiases, key=userBiases.get), max(userBiases.values()))\n",
    "min_ub = (min(userBiases, key=userBiases.get), min(userBiases.values()))\n",
    "max_bb = (max(bookBiases, key=bookBiases.get), max(bookBiases.values()))\n",
    "min_bb = (min(bookBiases, key=bookBiases.get), min(bookBiases.values()))\n",
    "\n",
    "summary_table = [max_ub, min_ub, max_bb, min_bb]\n",
    "\n",
    "pd.DataFrame(\n",
    "        summary_table,\n",
    "        columns=[\"ID\", \"Value\"],\n",
    "        index=[\"Max.User Bias\", \"Min.User Bias\", \"Max.Book Bias\", \"Min.Book Bias\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tuning(hyperparameter_list):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global bookBiases\n",
    "    alpha = ratingMean\n",
    "    userBiases = defaultdict(float)\n",
    "    bookBiases = defaultdict(float)\n",
    "    training_MSE = []\n",
    "    valid_MSE = []\n",
    "    for lamb, l1 in hyperparameter_list:\n",
    "        print(\"For hyperparameter\")\n",
    "        theta = scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nBooks),\n",
    "                derivative, args = (train_labels, lamb, l1, train_data))\n",
    "        unpack(theta[0])\n",
    "        training_MSE.append(theta[1])\n",
    "        valid_labels = [float(d[2]) for d in valid_data]\n",
    "        valid_predictions = [prediction(u, b) for u,b,_ in valid_data]\n",
    "        valid_MSE.append(MSE(numpy.array(valid_predictions), numpy.array(valid_labels)))\n",
    "    MSE_table = {'Hyperparameter': hyperparameter_list, 'Training MSE': training_MSE, 'Validation MSE': valid_MSE}\n",
    "    return pd.DataFrame(MSE_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_list = [0.000010, 0.000005, 0.000020, 0.000015]\n",
    "l1_strengths = [0]\n",
    "\n",
    "thresholds_criteria = list(itertools.product(hyperparameter_list, l1_strengths))\n",
    "\n",
    "parameter_tuning(thresholds_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "userGamma = {}\n",
    "bookGamma = {}\n",
    "\n",
    "K = 5\n",
    "for u in ratingsPerUser:\n",
    "    userGamma[u] = [random.random() * 0.1 - 0.05 for k in range(K)]\n",
    "for b in ratingsPerBook:\n",
    "    bookGamma[b] = [random.random() * 0.1 - 0.05 for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, book):\n",
    "    if user in userBiases and book in bookBiases:\n",
    "        return alpha + userBiases[user] + bookBiases[book] + inner(userGamma[user], bookGamma[book])\n",
    "    elif user in bookBiases and book not in bookBiases:\n",
    "        return alpha + userBiases[user]\n",
    "    elif user not in bookBiases and book in bookBiases:\n",
    "        return alpha + bookBiases[book]\n",
    "    else:\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global bookBiases\n",
    "    global userGamma\n",
    "    global bookGamma\n",
    "    index = 0\n",
    "    alpha = theta[index]\n",
    "    index += 1\n",
    "    userBiases = dict(zip(users, theta[index : index + nUsers]))\n",
    "    index += nUsers\n",
    "    bookBiases = dict(zip(books, theta[index : index + nBooks]))\n",
    "    index += nBooks\n",
    "    for u in users:\n",
    "        userGamma[u] = theta[index : index + K]\n",
    "        index += K\n",
    "    for b in books:\n",
    "        bookGamma[b] = theta[index : index + K]\n",
    "        index += K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x, y):\n",
    "    return sum([a * b for a, b in zip(x, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb1, lamb2, l1, data):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(user, book) for user, book, _ in data]\n",
    "    cost = MSE(numpy.array(predictions), numpy.array(labels))\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    #for u in users:\n",
    "     #   cost += lamb * userBiases[u] ** 2\n",
    "      #  for k in range(K):\n",
    "       #     cost += lamb * userGamma[u][k] ** 2\n",
    "    #for b in books:\n",
    "     #   cost += lamb * bookBiases[b] ** 2\n",
    "      #  for k in range(K):\n",
    "       #     cost += lamb * bookGamma[b][k] ** 2\n",
    "    cost += lamb1 * (1 - l1)* (sum(numpy.array(list(userBiases.values())) ** 2) + sum(numpy.array(list(bookBiases.values())) ** 2))\n",
    "    cost += lamb1 * l1 * (sum(numpy.abs(numpy.array(list(userBiases.values())))) + sum(numpy.abs(numpy.array(list(bookBiases.values())))))\n",
    "    cost += lamb2 * (sum(sum(numpy.abs(numpy.array(list(userGamma.values()))))) + sum(sum(numpy.abs(numpy.array(list(bookGamma.values()))))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb1, lamb2, l1, data):\n",
    "    unpack(theta)\n",
    "    N = len(data)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dBookBiases = defaultdict(float)\n",
    "    dUserGamma = {}\n",
    "    dBookGamma = {}\n",
    "    for u in ratingsPerUser:\n",
    "        dUserGamma[u] = [0.0 for k in range(K)]\n",
    "    for b in ratingsPerBook:\n",
    "        dBookGamma[b] = [0.0 for k in range(K)]\n",
    "    for user, book, rating in data:\n",
    "        pred = prediction(user, book)\n",
    "        diff = pred - float(rating)\n",
    "        dalpha += 2 / N * diff\n",
    "        dUserBiases[user] += 2 / N * diff\n",
    "        dBookBiases[book] += 2 / N * diff\n",
    "        for k in range(K):\n",
    "            dUserGamma[user][k] += 2 / N * bookGamma[book][k] * diff\n",
    "            dBookGamma[book][k] += 2 / N * userGamma[user][k] * diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2 * lamb1 * (1 - l1) * userBiases[u] + lamb1 * l1 * sign(userBiases[u])\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] +=  lamb2 * sign(userGamma[u][k])\n",
    "    for b in bookBiases:\n",
    "        dBookBiases[b] += 2 * lamb1 * (1 - l1) * bookBiases[b] + lamb1 * l1 * sign(bookBiases[b])\n",
    "        for k in range(K):\n",
    "            dBookGamma[b][k] += lamb2 * sign(bookGamma[b][k])\n",
    "    dtheta = (\n",
    "        [dalpha] + [dUserBiases[u] for u in users] + [dBookBiases[b] for b in books]\n",
    "    )\n",
    "    for u in users:\n",
    "        dtheta += dUserGamma[u]\n",
    "    for b in books:\n",
    "        dtheta += dBookGamma[b]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4790475125391764"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = [float(d[2]) for d in train_data]\n",
    "train_alwaysPredictMean = [float(alpha) for d in train_data]\n",
    "MSE(numpy.array(train_alwaysPredictMean), numpy.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.908652222207209\n",
      "MSE = 0.9085914689283121\n"
     ]
    }
   ],
   "source": [
    "theta = scipy.optimize.fmin_l_bfgs_b(\n",
    "    cost,\n",
    "    list(theta_model1)\n",
    "    + [random.random() * 0.1 - 0.05 for k in range(K * (nUsers + nBooks))],\n",
    "    derivative,\n",
    "    args=(train_labels, 0.000009, 0.000008, 0, train_data), maxfun = 40, maxiter = 40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack(theta[0])\n",
    "valid_labels = [float(d[2]) for d in valid_data]\n",
    "valid_predictions = [prediction(u, b) for u, b, _ in valid_data]\n",
    "MSE(numpy.array(valid_predictions), numpy.array(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tuning(hyperparameter_list):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global bookBiases\n",
    "    global userGamma\n",
    "    global bookGamma\n",
    "    \n",
    "    alpha = ratingMean\n",
    "    userBiases = defaultdict(float)\n",
    "    bookBiases = defaultdict(float)\n",
    "    userGamma = {}\n",
    "    bookGamma = {}\n",
    "    \n",
    "    K = 2\n",
    "    for u in ratingsPerUser:\n",
    "        userGamma[u] = [random.random() * 0.1 - 0.05 for k in range(K)]\n",
    "    for b in ratingsPerBook:\n",
    "        bookGamma[b] = [random.random() * 0.1 - 0.05 for k in range(K)]\n",
    "    \n",
    "    training_MSE = []\n",
    "    valid_MSE = []\n",
    "    for lamb2 in hyperparameter_list:\n",
    "        print(\"For hyperparameter\")\n",
    "        theta = scipy.optimize.fmin_l_bfgs_b(\n",
    "            cost,\n",
    "            list(theta_model1) + [random.random() * 0.1 - 0.05 for k in range(K * (nUsers + nBooks))],\n",
    "            derivative,\n",
    "            args=(train_labels, 0.00001, lamb2, 0.6, train_data), maxfun = 40, maxiter = 40\n",
    "        )\n",
    "        unpack(theta[0])\n",
    "        training_MSE.append(theta[1])\n",
    "        valid_labels = [float(d[2]) for d in valid_data]\n",
    "        valid_predictions = [prediction(u, b) for u, b, _ in valid_data]\n",
    "        valid_MSE.append(MSE(numpy.array(valid_predictions), numpy.array(valid_labels)))\n",
    "    MSE_table = {\n",
    "        \"Hyperparameter\": hyperparameter_list,\n",
    "        \"Training MSE\": training_MSE,\n",
    "        \"Validation MSE\": valid_MSE,\n",
    "    }\n",
    "    return pd.DataFrame(MSE_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_list = [1e-5, 1e-6, 0.00000078, 0.0000090, 0.000006]\n",
    "\n",
    "parameter_tuning(hyperparameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.txt\", \"w\")\n",
    "\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u, b = l.strip().split(\"-\")\n",
    "    predictions.write(u + \"-\" + b + \",\" + str(prediction(u, b)) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
