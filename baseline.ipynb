{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions to extract zip, and extract data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, \"rt\"):\n",
    "        yield eval(l)\n",
    "\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, \"rt\")\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        yield l.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for user, book, rating in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    data.append([user, book, rating])\n",
    "\n",
    "train_data = data[:190000]\n",
    "valid_data = data[190000:]\n",
    "\n",
    "books = set(np.array(data).T[1])\n",
    "users = set(np.array(data).T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visaulizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerBook = defaultdict(set)\n",
    "booksPerUser = defaultdict(set)\n",
    "\n",
    "for user, book, r in train_data:\n",
    "    usersPerBook[book].add(user)\n",
    "    booksPerUser[user].add(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1, Generating negative cases for user in each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont run this... everytime.\n",
    "\n",
    "neg_valid_data = []\n",
    "\n",
    "for user, _, _ in valid_data:\n",
    "    unreadbooks = list(books.difference(booksPerUser[user]))\n",
    "    datum = [user, random.choice(unreadbooks), -1]\n",
    "    neg_valid_data.append(datum)\n",
    "\n",
    "valid_data = valid_data + neg_valid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training over training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user, book, _ in train_data:\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "def top_n_books(mostPopular, c):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > totalRead * c:\n",
    "            break\n",
    "    return return1, count\n",
    "\n",
    "return1, count = top_n_books(mostPopular, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_read(valid_data, return1):\n",
    "    y_valid_pred = []\n",
    "    for user, book, _ in valid_data:\n",
    "        if book in return1:\n",
    "            y_valid_pred.append(1)\n",
    "        else:\n",
    "            y_valid_pred.append(0)\n",
    "    return y_valid_pred\n",
    "\n",
    "\n",
    "y_valid = np.array([1] * 10000 + [0] * 10000)\n",
    "y_valid_pred = pred_read(valid_data, return1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.855\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(y_valid == y_valid_pred) * 100 / len(y_valid_pred)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function to calculate diagnostic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(y, y_pred, t):\n",
    "    accuracy = sum(y_pred == y) / len(y)\n",
    "    c_m = confusion_matrix(y, y_pred)\n",
    "    TP = c_m[1][1]\n",
    "    FP = c_m[0][1]\n",
    "    FN = c_m[1][0]\n",
    "    TN = c_m[0][0]\n",
    "    BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1 = 2 * precision * recall / (precision + recall)\n",
    "    return t, accuracy, BER, precision, recall, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2, Trying better definitons of popularity by manipulating the propotion of users reading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = [0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "top_books = [(top_n_books(mostPopular, c), c) for c in criteria]\n",
    "\n",
    "y_valid_accuracies = [\n",
    "    performance_metrics(y_valid, pred_read(valid_data, return1[0]), c)\n",
    "    for return1, c in top_books\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Popularity in Training Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>BER</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.60935</td>\n",
       "      <td>0.39065</td>\n",
       "      <td>0.794982</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.429999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.63050</td>\n",
       "      <td>0.36950</td>\n",
       "      <td>0.753792</td>\n",
       "      <td>0.3876</td>\n",
       "      <td>0.511954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.64095</td>\n",
       "      <td>0.35905</td>\n",
       "      <td>0.737971</td>\n",
       "      <td>0.4371</td>\n",
       "      <td>0.549017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.64855</td>\n",
       "      <td>0.35145</td>\n",
       "      <td>0.721089</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.579580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65335</td>\n",
       "      <td>0.34665</td>\n",
       "      <td>0.700641</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.607040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.65315</td>\n",
       "      <td>0.34685</td>\n",
       "      <td>0.680071</td>\n",
       "      <td>0.5784</td>\n",
       "      <td>0.625128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64965</td>\n",
       "      <td>0.35035</td>\n",
       "      <td>0.656915</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.641347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.64360</td>\n",
       "      <td>0.35640</td>\n",
       "      <td>0.635268</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.654249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.62130</td>\n",
       "      <td>0.37870</td>\n",
       "      <td>0.593107</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.671096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.57955</td>\n",
       "      <td>0.42045</td>\n",
       "      <td>0.550066</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.675190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.54525</td>\n",
       "      <td>0.45475</td>\n",
       "      <td>0.525607</td>\n",
       "      <td>0.9288</td>\n",
       "      <td>0.671317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Popularity in Training Set  Accuracy      BER  Precision  Recall        F1\n",
       "0                         0.30   0.60935  0.39065   0.794982  0.2947  0.429999\n",
       "1                         0.40   0.63050  0.36950   0.753792  0.3876  0.511954\n",
       "2                         0.45   0.64095  0.35905   0.737971  0.4371  0.549017\n",
       "3                         0.50   0.64855  0.35145   0.721089  0.4845  0.579580\n",
       "4                         0.55   0.65335  0.34665   0.700641  0.5355  0.607040\n",
       "5                         0.60   0.65315  0.34685   0.680071  0.5784  0.625128\n",
       "6                         0.65   0.64965  0.35035   0.656915  0.6265  0.641347\n",
       "7                         0.70   0.64360  0.35640   0.635268  0.6744  0.654249\n",
       "8                         0.80   0.62130  0.37870   0.593107  0.7727  0.671096\n",
       "9                         0.90   0.57955  0.42045   0.550066  0.8740  0.675190\n",
       "10                        0.95   0.54525  0.45475   0.525607  0.9288  0.671317"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    y_valid_accuracies,\n",
    "    columns=[\n",
    "        \"Popularity in Training Set\",\n",
    "        \"Accuracy\",\n",
    "        \"BER\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"F1\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The better threshold is 0.55 as you can see above( has best accuracy), but still we do not have a tremendous improvement. We can look for desiging better recommendation system than simply predicting based on popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3, Implementing Jaccard similarity on the books the user has read before to ascertain whether the user would be reading the new book or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1)**0.5 * len(s2)**0.5\n",
    "    try:\n",
    "        sim = numer/denom\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1, count = top_n_books(mostPopular, 0.70)\n",
    "\n",
    "def pred_jaccard(threshold):\n",
    "    y_valid_pred = []\n",
    "    for user, book, _ in valid_data:\n",
    "        recommend = 0\n",
    "        books = booksPerUser[user]\n",
    "        for each_book in books:\n",
    "            if each_book == book or each_book not in return1:\n",
    "                continue\n",
    "            else:\n",
    "                users = usersPerBook[each_book]\n",
    "                sim = Jaccard(users, usersPerBook[book])\n",
    "                if sim > threshold:\n",
    "                    recommend = 1\n",
    "                    break\n",
    "        y_valid_pred.append(recommend)\n",
    "    return y_valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>BER</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.61250</td>\n",
       "      <td>0.38750</td>\n",
       "      <td>0.575707</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.688254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.61515</td>\n",
       "      <td>0.38485</td>\n",
       "      <td>0.578810</td>\n",
       "      <td>0.8457</td>\n",
       "      <td>0.687254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.61905</td>\n",
       "      <td>0.38095</td>\n",
       "      <td>0.583106</td>\n",
       "      <td>0.8353</td>\n",
       "      <td>0.686783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.62190</td>\n",
       "      <td>0.37810</td>\n",
       "      <td>0.588874</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>0.681144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.62245</td>\n",
       "      <td>0.37755</td>\n",
       "      <td>0.591675</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>0.676714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.62430</td>\n",
       "      <td>0.37570</td>\n",
       "      <td>0.595896</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>0.672764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.61990</td>\n",
       "      <td>0.38010</td>\n",
       "      <td>0.609139</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.637759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.60405</td>\n",
       "      <td>0.39595</td>\n",
       "      <td>0.618548</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.578261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity Threshold  Accuracy      BER  Precision  Recall        F1\n",
       "0                0.0070   0.61250  0.38750   0.575707  0.8555  0.688254\n",
       "1                0.0075   0.61515  0.38485   0.578810  0.8457  0.687254\n",
       "2                0.0080   0.61905  0.38095   0.583106  0.8353  0.686783\n",
       "3                0.0090   0.62190  0.37810   0.588874  0.8077  0.681144\n",
       "4                0.0095   0.62245  0.37755   0.591675  0.7903  0.676714\n",
       "5                0.0100   0.62430  0.37570   0.595896  0.7724  0.672764\n",
       "6                0.0125   0.61990  0.38010   0.609139  0.6692  0.637759\n",
       "7                0.0150   0.60405  0.39595   0.618548  0.5429  0.578261"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds = [0.0070, 0.0075, 0.0080, 0.0090, 0.0095, 0.01, 0.0125, 0.015]\n",
    "\n",
    "y_valid_accuracies = [\n",
    "    performance_metrics(y_valid, pred_jaccard(t), t) for t in thresholds\n",
    "]\n",
    "\n",
    "pd.DataFrame(\n",
    "    y_valid_accuracies,\n",
    "    columns=[\"Similarity Threshold\", \"Accuracy\", \"BER\", \"Precision\", \"Recall\", \"F1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best of the lot is 0.01 for the similarity threshold, whihc gives the best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction on the Jaccard Similirity based recommender system performs worse than popularity based. Hence we go for a best of both worlds model as the new recommendation system to predict whether user will read a book or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_combined(threshold, c):\n",
    "    y_valid_pred = []\n",
    "    return1, _ = top_n_books(mostPopular, c)\n",
    "    for user, book, _ in valid_data:\n",
    "        recommend_sim = 0\n",
    "        recommend_pop = 0\n",
    "        similarities = []\n",
    "\n",
    "        if book in return1:\n",
    "            # y_valid_pred.append(1)\n",
    "            recommend_pop = 1\n",
    "\n",
    "        books = booksPerUser[user]\n",
    "        for each_book in books:\n",
    "            if each_book == book or each_book not in return1:\n",
    "                continue\n",
    "            else:\n",
    "                users = usersPerBook[each_book]\n",
    "                sim = Jaccard(users, usersPerBook[book])\n",
    "                if sim > threshold:\n",
    "                    recommend_sim = 1\n",
    "                    break\n",
    "                       \n",
    "        y_valid_pred.append(recommend_sim and recommend_pop)\n",
    "\n",
    "    return y_valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.008, 0.009, 0.00002)\n",
    "criteria = np.arange(0.6, 0.8, 0.02)\n",
    "\n",
    "thresholds_criteria = list(itertools.product(thresholds, criteria))\n",
    "\n",
    "y_valid_accuracies = [(c,)+performance_metrics(y_valid, pred_combined(t, c), t) for t, c in thresholds_criteria]\n",
    "\n",
    "performance_matrix = pd.DataFrame(y_valid_accuracies, columns = ['Popularity Threshold','Similarity Threshold','Accuracy','BER','Precision','Recall','F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Popularity Threshold</th>\n",
       "      <th>Similarity Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>BER</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00856</td>\n",
       "      <td>0.66115</td>\n",
       "      <td>0.33885</td>\n",
       "      <td>0.673485</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.648660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00858</td>\n",
       "      <td>0.66110</td>\n",
       "      <td>0.33890</td>\n",
       "      <td>0.673450</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.648590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00860</td>\n",
       "      <td>0.66100</td>\n",
       "      <td>0.33900</td>\n",
       "      <td>0.673379</td>\n",
       "      <td>0.6253</td>\n",
       "      <td>0.648450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00862</td>\n",
       "      <td>0.66100</td>\n",
       "      <td>0.33900</td>\n",
       "      <td>0.673379</td>\n",
       "      <td>0.6253</td>\n",
       "      <td>0.648450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00826</td>\n",
       "      <td>0.66090</td>\n",
       "      <td>0.33910</td>\n",
       "      <td>0.670916</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.650664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00834</td>\n",
       "      <td>0.66090</td>\n",
       "      <td>0.33910</td>\n",
       "      <td>0.671755</td>\n",
       "      <td>0.6293</td>\n",
       "      <td>0.649835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00836</td>\n",
       "      <td>0.66090</td>\n",
       "      <td>0.33910</td>\n",
       "      <td>0.671755</td>\n",
       "      <td>0.6293</td>\n",
       "      <td>0.649835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00824</td>\n",
       "      <td>0.66085</td>\n",
       "      <td>0.33915</td>\n",
       "      <td>0.670844</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.650631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00800</td>\n",
       "      <td>0.66085</td>\n",
       "      <td>0.33915</td>\n",
       "      <td>0.669691</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.651779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00802</td>\n",
       "      <td>0.66085</td>\n",
       "      <td>0.33915</td>\n",
       "      <td>0.669691</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.651779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00804</td>\n",
       "      <td>0.66085</td>\n",
       "      <td>0.33915</td>\n",
       "      <td>0.669691</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.651779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00806</td>\n",
       "      <td>0.66085</td>\n",
       "      <td>0.33915</td>\n",
       "      <td>0.669691</td>\n",
       "      <td>0.6348</td>\n",
       "      <td>0.651779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00808</td>\n",
       "      <td>0.66080</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.670051</td>\n",
       "      <td>0.6336</td>\n",
       "      <td>0.651316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00820</td>\n",
       "      <td>0.66080</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.670737</td>\n",
       "      <td>0.6317</td>\n",
       "      <td>0.650633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00848</td>\n",
       "      <td>0.66080</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.672569</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.648825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00800</td>\n",
       "      <td>0.66080</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.676432</td>\n",
       "      <td>0.6165</td>\n",
       "      <td>0.645077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00802</td>\n",
       "      <td>0.66080</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.676432</td>\n",
       "      <td>0.6165</td>\n",
       "      <td>0.645077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00804</td>\n",
       "      <td>0.66080</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.676432</td>\n",
       "      <td>0.6165</td>\n",
       "      <td>0.645077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00806</td>\n",
       "      <td>0.66080</td>\n",
       "      <td>0.33920</td>\n",
       "      <td>0.676432</td>\n",
       "      <td>0.6165</td>\n",
       "      <td>0.645077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00822</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.33925</td>\n",
       "      <td>0.670702</td>\n",
       "      <td>0.6316</td>\n",
       "      <td>0.650564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00850</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.33925</td>\n",
       "      <td>0.672534</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>0.648755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00852</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.33925</td>\n",
       "      <td>0.672571</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.648719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00854</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.33925</td>\n",
       "      <td>0.672571</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.648719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00870</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.33925</td>\n",
       "      <td>0.673991</td>\n",
       "      <td>0.6227</td>\n",
       "      <td>0.647331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00872</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.33925</td>\n",
       "      <td>0.673991</td>\n",
       "      <td>0.6227</td>\n",
       "      <td>0.647331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00856</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.33925</td>\n",
       "      <td>0.680072</td>\n",
       "      <td>0.6071</td>\n",
       "      <td>0.641517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00810</td>\n",
       "      <td>0.66070</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.670017</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.651141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00812</td>\n",
       "      <td>0.66070</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.670017</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>0.651141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00838</td>\n",
       "      <td>0.66070</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.671615</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>0.649556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00840</td>\n",
       "      <td>0.66070</td>\n",
       "      <td>0.33930</td>\n",
       "      <td>0.671615</td>\n",
       "      <td>0.6289</td>\n",
       "      <td>0.649556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Popularity Threshold  Similarity Threshold  Accuracy      BER  Precision  \\\n",
       "314                  0.72               0.00856   0.66115  0.33885   0.673485   \n",
       "325                  0.72               0.00858   0.66110  0.33890   0.673450   \n",
       "336                  0.72               0.00860   0.66100  0.33900   0.673379   \n",
       "347                  0.72               0.00862   0.66100  0.33900   0.673379   \n",
       "149                  0.72               0.00826   0.66090  0.33910   0.670916   \n",
       "193                  0.72               0.00834   0.66090  0.33910   0.671755   \n",
       "204                  0.72               0.00836   0.66090  0.33910   0.671755   \n",
       "138                  0.72               0.00824   0.66085  0.33915   0.670844   \n",
       "6                    0.72               0.00800   0.66085  0.33915   0.669691   \n",
       "17                   0.72               0.00802   0.66085  0.33915   0.669691   \n",
       "28                   0.72               0.00804   0.66085  0.33915   0.669691   \n",
       "39                   0.72               0.00806   0.66085  0.33915   0.669691   \n",
       "50                   0.72               0.00808   0.66080  0.33920   0.670051   \n",
       "116                  0.72               0.00820   0.66080  0.33920   0.670737   \n",
       "270                  0.72               0.00848   0.66080  0.33920   0.672569   \n",
       "5                    0.70               0.00800   0.66080  0.33920   0.676432   \n",
       "16                   0.70               0.00802   0.66080  0.33920   0.676432   \n",
       "27                   0.70               0.00804   0.66080  0.33920   0.676432   \n",
       "38                   0.70               0.00806   0.66080  0.33920   0.676432   \n",
       "127                  0.72               0.00822   0.66075  0.33925   0.670702   \n",
       "281                  0.72               0.00850   0.66075  0.33925   0.672534   \n",
       "292                  0.72               0.00852   0.66075  0.33925   0.672571   \n",
       "303                  0.72               0.00854   0.66075  0.33925   0.672571   \n",
       "391                  0.72               0.00870   0.66075  0.33925   0.673991   \n",
       "402                  0.72               0.00872   0.66075  0.33925   0.673991   \n",
       "313                  0.70               0.00856   0.66075  0.33925   0.680072   \n",
       "61                   0.72               0.00810   0.66070  0.33930   0.670017   \n",
       "72                   0.72               0.00812   0.66070  0.33930   0.670017   \n",
       "215                  0.72               0.00838   0.66070  0.33930   0.671615   \n",
       "226                  0.72               0.00840   0.66070  0.33930   0.671615   \n",
       "\n",
       "     Recall        F1  \n",
       "314  0.6256  0.648660  \n",
       "325  0.6255  0.648590  \n",
       "336  0.6253  0.648450  \n",
       "347  0.6253  0.648450  \n",
       "149  0.6316  0.650664  \n",
       "193  0.6293  0.649835  \n",
       "204  0.6293  0.649835  \n",
       "138  0.6316  0.650631  \n",
       "6    0.6348  0.651779  \n",
       "17   0.6348  0.651779  \n",
       "28   0.6348  0.651779  \n",
       "39   0.6348  0.651779  \n",
       "50   0.6336  0.651316  \n",
       "116  0.6317  0.650633  \n",
       "270  0.6267  0.648825  \n",
       "5    0.6165  0.645077  \n",
       "16   0.6165  0.645077  \n",
       "27   0.6165  0.645077  \n",
       "38   0.6165  0.645077  \n",
       "127  0.6316  0.650564  \n",
       "281  0.6266  0.648755  \n",
       "292  0.6265  0.648719  \n",
       "303  0.6265  0.648719  \n",
       "391  0.6227  0.647331  \n",
       "402  0.6227  0.647331  \n",
       "313  0.6071  0.641517  \n",
       "61   0.6333  0.651141  \n",
       "72   0.6333  0.651141  \n",
       "215  0.6289  0.649556  \n",
       "226  0.6289  0.649556  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_matrix.sort_values(\n",
    "    by=[\"Accuracy\", \"BER\", \"Recall\"], ascending=[False, True, False]\n",
    ")[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the popularity and similarity models by doing an AND operation on the two predictions to get more confident predictions. The above matrix shows the top 30 performing matrix for the hyperparameters values. Using 0.7 as popularity threshold and 0.0085 similarity threshold give the best performance in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5, With the model and hyperparameters in question 4 we run the prediction on the test data set. The resulting file is uploaded to Kaggle. (Username : mouserat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1, _ = top_n_books(mostPopular, 0.72)\n",
    "\n",
    "predictions = open(\"predictions_Read.txt\", \"w\")\n",
    "for l in open(\"pairs_Read.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "\n",
    "    u, b = l.strip().split(\"-\")\n",
    "    recommend_sim = 0\n",
    "    recommend_pop = 0\n",
    "\n",
    "    if b in return1:\n",
    "        recommend_pop = 1\n",
    "        # predictions.write(u + '-' + b + \",\" + str(recommend) + \"\\n\")\n",
    "\n",
    "    bs = booksPerUser[u]\n",
    "    for each_book in bs:\n",
    "        if each_book == b or each_book not in return1:\n",
    "            continue\n",
    "        else:\n",
    "            us = usersPerBook[each_book]\n",
    "            sim = Jaccard(us, usersPerBook[b])\n",
    "            if sim > 0.0087:\n",
    "                recommend_sim = 1\n",
    "                break\n",
    "    # predictions.write(u + '-' + b + \",\" + str(recommend) + \"\\n\")\n",
    "    predictions.write(u + \"-\" + b + \",\" + str(recommend_sim and recommend_pop) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
